{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not much to write about here, but it does exac...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The product does exactly as it should and is q...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The primary job of this device is to block the...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nice windscreen protects my MXL mic and preven...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This pop filter is great. It looks and perform...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews Sentiment\n",
       "0  Not much to write about here, but it does exac...  Positive\n",
       "1  The product does exactly as it should and is q...  Positive\n",
       "2  The primary job of this device is to block the...  Positive\n",
       "3  Nice windscreen protects my MXL mic and preven...  Positive\n",
       "4  This pop filter is great. It looks and perform...  Positive"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\user\\Desktop\\YEAR 3 SEM 1\\TXSA\\groupie/Reviews_Sentiments.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10254 entries, 0 to 10253\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Reviews    10254 non-null  object\n",
      " 1   Sentiment  10254 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 160.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    9403\n",
       "Negative     673\n",
       "Neutral      178\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~ PERFORMANCE MEASURES ~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "The accuracy of the classifier is:  0.9452464559760697\n",
      "\n",
      "The Positive Precision of the classifier is: 0.3790322580645161\n",
      "\n",
      "The Positive Recall of the classifier is: 0.3533834586466165\n",
      "\n",
      "The Positive F1 Score of the classifier is: 0.3657587548638132\n",
      "\n",
      "The Negative Precision of the classifier is: 0.9624773329613614\n",
      "\n",
      "The Negative Recall of the classifier is: 0.9784458309699376\n",
      "\n",
      "The Negative F1 Score of the classifier is: 0.970395893397089\n",
      "~~~~~~~~~~~~~~~~~~ NEUTRALS ~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "The Neutral Precision of the classifier is: 0.8106060606060606\n",
      "\n",
      "The Neutral Recall of the classifier is: 0.6369047619047619\n",
      "\n",
      "The Neutral F1 Score of the classifier is: 0.7133333333333333\n"
     ]
    }
   ],
   "source": [
    "def word_features(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "#Loops\n",
    "positive_sentiments = [(neutral['Reviews']) for index, neutral in data.iterrows() if neutral['Sentiment'] == 'Neutral']\n",
    "neutral_sentiments = [(negative['Reviews']) for index, negative in data.iterrows() if negative['Sentiment'] == 'Negative']\n",
    "negative_sentiments = [(positive['Reviews']) for index, positive in data.iterrows() if positive['Sentiment'] == 'Positive']\n",
    "\n",
    "\n",
    "#sentiments and features dictionary are joined.Add counters to all loops.\n",
    "positive_features = [(word_features(word_tokenize(positive_sentiments[i[0]])),'pos') for i in enumerate(positive_sentiments)]\n",
    "neutral_features = [(word_features(word_tokenize(neutral_sentiments[i[0]])),'neu') for i in enumerate(neutral_sentiments)]\n",
    "negative_features = [(word_features(word_tokenize(negative_sentiments[i[0]])),'neg') for i in enumerate(negative_sentiments)]\n",
    "\n",
    "#Divide dataset into test and train data. 75% for train, 25% for test.\n",
    "PositiveCutoff = int(len(positive_features)*3/4)\n",
    "NeutralCutoff = int(len(neutral_features)*3/4)\n",
    "NegativeCutoff = int(len(negative_features)*3/4)\n",
    "\n",
    "\n",
    "#testing and trainign featuresets\n",
    "train_featureset =  positive_features[:PositiveCutoff] + neutral_features[:NeutralCutoff] + negative_features[:NegativeCutoff] \n",
    "test_featureset=  positive_features[:PositiveCutoff]+ neutral_features[:NeutralCutoff] + negative_features[:NegativeCutoff] \n",
    "\n",
    "\n",
    "#Supervised sentiment classification model using  Naive Bayes classifier with NLTK.\n",
    "classifier_NB = nltk.NaiveBayesClassifier.train(test_featureset)\n",
    "refsets = collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_featureset):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier_NB.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "\n",
    "\n",
    "print(\"~~~~~~~~~~~~~~~~~~ PERFORMANCE MEASURES ~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"\\nThe accuracy of the classifier is: \", nltk.classify.accuracy(classifier_NB, test_features))\n",
    "print(\"\\nThe Positive Precision of the classifier is:\", nltk.scores.precision(refsets['pos'], testsets['pos']))\n",
    "print (\"\\nThe Positive Recall of the classifier is:\", nltk.scores.recall(refsets['pos'], testsets['pos']))\n",
    "print (\"\\nThe Positive F1 Score of the classifier is:\", nltk.scores.f_measure(refsets['pos'], testsets['pos']))\n",
    "\n",
    "print(\"\\nThe Negative Precision of the classifier is:\", nltk.scores.precision(refsets['neg'], testsets['neg']))\n",
    "print (\"\\nThe Negative Recall of the classifier is:\", nltk.scores.recall(refsets['neg'], testsets['neg']))\n",
    "print (\"\\nThe Negative F1 Score of the classifier is:\", nltk.scores.f_measure(refsets['neg'], testsets['neg']))\n",
    "\n",
    "\n",
    "\n",
    "print(\"~~~~~~~~~~~~~~~~~~ NEUTRALS ~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"\\n\\nThe Neutral Precision of the classifier is:\", nltk.scores.precision(refsets['neu'], testsets['neu']))\n",
    "print (\"\\nThe Neutral Recall of the classifier is:\", nltk.scores.recall(refsets['neu'], testsets['neu']))\n",
    "print (\"\\nThe Neutral F1 Score of the classifier is:\", nltk.scores.f_measure(refsets['neu'], testsets['neu']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
