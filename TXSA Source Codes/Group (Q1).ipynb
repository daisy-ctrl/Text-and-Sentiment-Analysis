{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 (Dhanish TP043509)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t PROBABILITIES OF UNSMOOTHED UNIGRAM MODEL\n",
      "\n",
      "He: 0.13333333333333333 I: 0.06666666666666667 Mulan: 0.06666666666666667 a: 0.2 book: 0.2 different: 0.06666666666666667 my: 0.06666666666666667 read: 0.2 UNK: 0.0 \n",
      "\n",
      "\t PROBABILITIES OF SMOOTHED UNIGRAM MODEL \n",
      "\n",
      "He: 0.125 I: 0.08333333333333333 Mulan: 0.08333333333333333 a: 0.16666666666666666 book: 0.16666666666666666 different: 0.08333333333333333 my: 0.08333333333333333 read: 0.16666666666666666 UNK: 0.041666666666666664 "
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "beginsentence = \"<s>\" #sentences are beginning with <s>\n",
    "endsentence = \"</s>\" #sentences are ending with </s>\n",
    "UNK = None\n",
    "\n",
    "class Unigram:\n",
    "    def __init__(self, sentences, smoothing=False):\n",
    "        self.unigramfrequency = dict()\n",
    "        self.lengthofcorpus = 0\n",
    "        for sentence in sentences:\n",
    "            for word in sentence:\n",
    "                self.unigramfrequency[word] = self.unigramfrequency.get(word, 0) + 1\n",
    "                if word != beginsentence and word != endsentence:\n",
    "                    self.lengthofcorpus += 1 \n",
    "        self.uniquewords = len(self.unigramfrequency) - 2 #subtract 2 because unigramfrequency dictionary contains values for beginsentence and endsentence\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def unigramprobability(self, word):\n",
    "            numerator = self.unigramfrequency.get(word, 0)\n",
    "            denominator = self.lengthofcorpus\n",
    "            if self.smoothing:\n",
    "                numerator += 1 #add one more to total number of seen unique words for UNK - unseen events\n",
    "                denominator += self.uniquewords + 1\n",
    "            return float(numerator) / float(denominator)\n",
    "\n",
    "  \n",
    "    def vocabulary(self):\n",
    "        vocab = list(self.unigramfrequency.keys())\n",
    "        vocab.remove(beginsentence)\n",
    "        vocab.remove(endsentence)\n",
    "        vocab.sort()\n",
    "        vocab.append(UNK)\n",
    "        vocab.append(beginsentence)\n",
    "        vocab.append(endsentence)\n",
    "        return vocab\n",
    "\n",
    "def displayunigramprob(sorted_vocab_keys, model):\n",
    "    for vocab_key in sorted_vocab_keys:\n",
    "        if vocab_key != beginsentence and vocab_key != endsentence:\n",
    "            print(\"{}: {}\".format(vocab_key if vocab_key != UNK else \"UNK\", model.unigramprobability(vocab_key)), end=\" \")\n",
    "\n",
    "def readfile(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return [re.split(\"\\s+\", line.rstrip('\\n')) for line in f]\n",
    "\n",
    "text = readfile(\"C:/Users/user/OneDrive/YEAR 3/1ST SEMESTER/TXSA/TXSA_Assignment/Group Assignment Data/Text Corpus.txt\")\n",
    "unsmoothed = Unigram(text)\n",
    "smoothed = Unigram(text, smoothing=True)\n",
    "vocabkey = unsmoothed.vocabulary()\n",
    "\n",
    "print(\"\\n\\t PROBABILITIES OF UNSMOOTHED UNIGRAM MODEL\\n\")\n",
    "displayunigramprob(vocabkey, unsmoothed)\n",
    "\n",
    "print(\"\\n\\n\\t PROBABILITIES OF SMOOTHED UNIGRAM MODEL \\n\")\n",
    "displayunigramprob(vocabkey, smoothed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
